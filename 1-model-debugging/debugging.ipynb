{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d543406-aefb-4ad5-ba7c-eb75e5fa08f5",
   "metadata": {},
   "source": [
    "# Debugging\n",
    "\n",
    "Author: **Christian Lessig et al.**\n",
    "\n",
    "`christian.lessig@ecmwf.int`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e9100",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Most often, we spend more time debugging code than writing it. This is particularly true for python.\n",
    "\n",
    "Debugging usually consists of three steps:\n",
    "1. Localize the problem.\n",
    "2. Understand what precisely goes wrong.\n",
    "3. Fix the problem.\n",
    "The third step is usually the easy one once the first two have been accomplished.\n",
    "\n",
    "To localize the problem and understand the issue, it is often important to have an understanding of the software stack that is used to run your code. Many error messages will result from somewhere in the stack and not directly from the user code.\n",
    "\n",
    "<img src=\"ml_stack.png\" width=\"400px\" >\n",
    "\n",
    "In simple cases when execution breaks, localizing the problem means to parse the error messages and map it to the code and the call stack. The problem might very well originate elsewhere but where the code breaks is the entry point for you to localize and understand the root cause.\n",
    "\n",
    "Ones an entry point into the problem has been found, one can investigate what goes wrong. This means almost always to set a break point before the offending line and investigate the state of the program and the code. Simple typos might not require this but in all other circumstances it is easier to use a breakpoint. In python one can break with:\n",
    "\n",
    "```\n",
    "import pdb; pdb.set_trace()\n",
    "```\n",
    "\n",
    "This opens a debugger shell in the code line following the one where the statement is. Alternatively, one can use:\n",
    "\n",
    "```\n",
    "code.interact( local=locals())\n",
    "```\n",
    "\n",
    "This opens an interactive python shell in the calling line but does not provide the functionality of a debugger (e.g. a stack trace). However, it can be useful for quick inspection or or code development.\n",
    "\n",
    "The common cause for bugs is that an assumption about the input/output data is violated. This can be the shape of a tensor (easy) or unexpected values (difficult) or something more subtle (very difficult). In the interactive debugger shell you can investigate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04366dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import reload\n",
    "import code\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a94abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nacl/training/ml-training-course/pyenv/lib/python3.11/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11080). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "reload( model)\n",
    "from model import MLP\n",
    "\n",
    "net = MLP( dim_in=512, dim_out=512)\n",
    "\n",
    "# check if GPU is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab76a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if we can evaluate the network\n",
    "\n",
    "t_in = torch.rand( (16, 4, 512)).to(device)\n",
    "t_out = net( t_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a252dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 1.0001879930496216\n"
     ]
    }
   ],
   "source": [
    "# test if data loading works\n",
    "\n",
    "import dataset\n",
    "reload( dataset)\n",
    "from dataset import CustomDataSet\n",
    "\n",
    "custom_dataset = CustomDataSet( len=32768, batch_size=128, dim_data=512)\n",
    "data_iter = iter(custom_dataset)\n",
    "\n",
    "lossfct = torch.nn.MSELoss()\n",
    "\n",
    "# load sample\n",
    "(source, target) = next(data_iter)\n",
    "source, target = source.to(device), target.to(device)\n",
    "\n",
    "# evaluate network\n",
    "pred = net( source)\n",
    "\n",
    "# compute loss\n",
    "loss = lossfct( pred, target)\n",
    "\n",
    "print( f'loss : {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1023113-3009-4c05-9e6f-983b23e96978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch=0 with loss=2.2095817257650197e-05.\n",
      "Finished epoch=1 with loss=1.923728398800506e-10.\n",
      "Finished epoch=2 with loss=1.1075946410032955e-10.\n",
      "Finished epoch=3 with loss=7.202569096698141e-11.\n",
      "Finished epoch=4 with loss=4.95193538951888e-11.\n",
      "Finished epoch=5 with loss=3.534422060580411e-11.\n",
      "Finished epoch=6 with loss=2.5699102568221832e-11.\n",
      "Finished epoch=7 with loss=1.912282832083889e-11.\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "optimizer = torch.optim.AdamW( net.parameters(), lr=0.00005)\n",
    "\n",
    "# parallel data loader\n",
    "loader_params = { 'batch_size': None, 'batch_sampler': None, 'shuffle': False, \n",
    "                   'num_workers': 8, 'pin_memory': True}\n",
    "dataloader = torch.utils.data.DataLoader( custom_dataset, **loader_params, sampler = None)\n",
    "\n",
    "num_epochs = 8\n",
    "\n",
    "optimizer.zero_grad()\n",
    "for epoch in range( num_epochs) :\n",
    "\n",
    "  # data_iter = iter( dataset)\n",
    "  data_iter = iter( dataloader)\n",
    "  \n",
    "  for bidx, (source, target) in enumerate(data_iter) :\n",
    "\n",
    "    source, target = source.to(device), target.to(device)\n",
    "    \n",
    "    pred = net( source)\n",
    "    loss = lossfct( pred, target)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  print( f'Finished epoch={epoch} with loss={loss}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc2c79d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 128 is out of bounds for dimension 0 with size 128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange( \u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m loss \u001b[38;5;241m=\u001b[39m lossfct( \u001b[43msource\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m, target[idx])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 128 is out of bounds for dimension 0 with size 128"
     ]
    }
   ],
   "source": [
    "idx = torch.arange( 512)\n",
    "loss = lossfct( source[idx], target[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
